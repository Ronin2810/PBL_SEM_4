{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3493e682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But new physics quantum physics has approved the whole thing and that makes it easier for you to understand human body now we think in the western medicine in western medical non-science we think human body is made up of different parts like you know you have automobile engineer mechanical engineers with different parts you make a car first week the case is in the body is in the engine and things like that that's how it is made so that is not how the human body is made if you understand in evolutionary biology you are the one cell one single nucleated cell when you made in mother's womb on the first day that cause i got that the first nucleated cell and this cell one cell divides and divides and divide and today you are a colony of 120 trillion such cells to another cell is a human being kept in all that you do so much so you are not i you are we you are a colony of this difference please remember that when you say i and that i that feeling in the starts when we that feeling wellness company. and we think it was the problem now it doesn't actually it creates another problem in short i always tell my students there is no pill for every row but the following every people forget this is called at was drug reaction as a matter of audit now shows in the west that the leading cause of death is not cancer heart attack at was drug reactions is called idea because we know in the western nonsense one drug for one disease under ideal circumstances which is called evidence based medicine but unfortunately in a patient with only one drug patients if you see it's a laundry list of drugs about 1850 and there is no science to say what happens when you combine two trucks what do you know how we play reliance studies show that when you give one tablet patient and tell him take it daily remembrance of the complaints is only 73% 27% forget that won't take correctly when you make it to tablets the day it falls 42% when you make it more than 3 tablets the day it comes down to 22% which mean a 78% of people whom you prescribed is multiple on release they don't take this medicine if they did they would be here.\n",
      "Text Word Count:  766\n",
      "Summary Word Count: 408\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "r=sr.Recognizer()\n",
    "path=\"D:/ytmp3free (mp3cut.net).wav\"\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "\n",
    "def makesummary(text):\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    nlp = spacy.load('en_core_web_sm') \n",
    "    doc = nlp(text) \n",
    "    tokens = [token.text for token in doc]\n",
    "    punctuation='!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'\n",
    "\n",
    "    word_fq = {}\n",
    "    for word in  doc:\n",
    "        if word.text.lower() not in stopwords:\n",
    "            if word.text.lower() not in punctuation:\n",
    "                if word.text not in word_fq.keys():\n",
    "                    word_fq[word.text] = 1\n",
    "                else:\n",
    "                    word_fq[word.text]+=1\n",
    "\n",
    "                    \n",
    "    max_fq = max(word_fq.values())\n",
    "    for word in word_fq.keys():\n",
    "            word_fq[word] = word_fq[word]/max_fq\n",
    "            \n",
    "            \n",
    "    s_tokens = [sent for sent in doc.sents]\n",
    "\n",
    "    s_score = {}\n",
    "    for sent in s_tokens:\n",
    "        for word in sent:\n",
    "            if word.text.lower() in word_fq.keys():\n",
    "                if sent not in s_score.keys():\n",
    "                    s_score[sent]= word_fq[word.text.lower()]\n",
    "                else:\n",
    "                    s_score[sent]+= word_fq[word.text.lower()]\n",
    "                    \n",
    "\n",
    "    s_length = int(len(s_tokens)*0.2)\n",
    "    summary = nlargest(s_length,s_score,key =s_score.get)\n",
    "    f_sum = [word.text for word in summary]\n",
    "    summary = \" \".join(f_sum)\n",
    "    return summary\n",
    "    \n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_wav(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 1500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=1500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk\n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_google(audio_listened)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "#     print(type(text))\n",
    "    return whole_text\n",
    "\n",
    "text = get_large_audio_transcription(path)\n",
    "final = makesummary(text)\n",
    "final_len = len(final.split( ))\n",
    "text_len = len(text.split( ))\n",
    "print(final)\n",
    "print(\"Text Word Count: \",(text_len))\n",
    "print(\"Summary Word Count:\",(final_len))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323301a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b44f89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b2aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79733840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
